{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to the core interfaces of mloda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mloda is a robust and flexible data framework tailored for professionals to efficiently manage data and feature engineering. It enables users to abstract processes away from data, in contrast to the current industry setup where processes are usually bound to specific data sets.\n",
    "\n",
    "This introductory notebook provides a practical demonstration of how MLoda helps machine learning data workflows by emphasizing data processes over raw data manipulation.\n",
    "\n",
    "- It begins by loading data from various sources, such as order, payment, location, and categorical datasets. \n",
    "- Next, we showcase mloda's versatility in handling diverse compute frameworks, including PyArrow tables and Pandas DataFrames.\n",
    "- Then we leverage mloda's advanced capabilities to integrate data from various sources into cohesive and unified feature sets (details on feature sets are covered in chapter 3). \n",
    "\n",
    "Finally, we will conclude by discussing the broader implications of what was done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/envs/python310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mloda_plugins.feature_group.experimental.llm.tools.available.read_file_tool', 'mloda_plugins.feature_group.input_data.read_context_files', 'mloda_plugins.feature_group.input_data.read_file', 'mloda_plugins.feature_group.input_data.read_db_feature', 'mloda_plugins.feature_group.input_data.read_db', 'mloda_plugins.feature_group.input_data.read_file_feature', 'mloda_plugins.feature_group.input_data.read_files.json', 'mloda_plugins.feature_group.input_data.read_files.csv', 'mloda_plugins.feature_group.input_data.read_files.parquet', 'mloda_plugins.feature_group.input_data.read_files.feather', 'mloda_plugins.feature_group.input_data.read_files.text_file_reader', 'mloda_plugins.feature_group.input_data.read_files.orc', 'mloda_plugins.feature_group.input_data.read_dbs.sqlite']\n",
      "['mloda_plugins.feature_group.input_data.read_dbs.sqlite']\n"
     ]
    }
   ],
   "source": [
    "# Load all available plugins into the python environment\n",
    "from mloda.user import PluginLoader\n",
    "\n",
    "plugin_loader = PluginLoader.all()\n",
    "\n",
    "\n",
    "# Since there are potentially many plugins loaded, we'll focus on specific categories for clarity.\n",
    "# Here, we demonstrate by listing the available 'read' and 'sql' plugins.\n",
    "print(plugin_loader.list_loaded_modules(\"read\"))\n",
    "print(plugin_loader.list_loaded_modules(\"sql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional!\n",
    "# We use synthetic dummy data to demonstrate the basic usage.\n",
    "# You can run this cell in your own jupyter notebook.\n",
    "# They are however not relevant for further understanding.\n",
    "#\n",
    "# from examples.mloda_basics import create_synthetic_data\n",
    "\n",
    "# create_synthetic_data.create_ml_lifecylce_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see 4 files in the base_data folder. One sqlite example for a db and 3 different file formats.\n",
    "\n",
    "Now we want to load the data to look at the content, so we can look at the data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: We want to load typical order information like order_id, product_id, quantity, and item_price.\n",
    "from typing import List\n",
    "from mloda.user import Feature\n",
    "\n",
    "order_features: List[str | Feature] = [\"order_id\", \"product_id\", \"quantity\", \"item_price\"]\n",
    "\n",
    "payment_features: List[str | Feature] = [\"payment_id\", \"payment_type\", \"payment_status\", \"valid_datetime\"]\n",
    "\n",
    "location_features: List[str | Feature] = [\"user_location\", \"merchant_location\", \"update_date\"]\n",
    "\n",
    "categorical_features: List[str | Feature] = [\"user_age_group\", \"product_category\", \"transaction_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: We specify the data sources to load\n",
    "import os\n",
    "from mloda.user import DataAccessCollection\n",
    "from mloda_plugins.feature_group.input_data.read_dbs.sqlite import SQLITEReader\n",
    "\n",
    "# Initialize a DataAccessCollection object\n",
    "data_access_collection = DataAccessCollection()\n",
    "\n",
    "# Define the folders containing the data\n",
    "# Note: We use two paths to accommodate different possible root locations as it depends where the code is executed.\n",
    "base_data_path = os.path.join(os.getcwd(), \"docs\", \"docs\", \"examples\", \"mloda_basics\", \"base_data\")\n",
    "if not os.path.exists(base_data_path):\n",
    "    base_data_path = os.path.join(os.getcwd(), \"base_data\")\n",
    "\n",
    "# Add the folder to the DataAccessCollection\n",
    "data_access_collection.add_folder(base_data_path)\n",
    "\n",
    "# As a db cannot work with a folder, we need to add a connection for the db.\n",
    "data_access_collection.add_credential_dict(\n",
    "    credential_dict={SQLITEReader.db_path(): os.path.join(base_data_path, \"example.sqlite\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "quantity: int64\n",
      "product_id: int64\n",
      "order_id: int64\n",
      "item_price: double\n",
      "----\n",
      "quantity: [[6,2]]\n",
      "product_id: [[282,355]]\n",
      "order_id: [[1,2]]\n",
      "item_price: [[74.86,154.56]] <class 'pyarrow.lib.Table'>\n",
      "pyarrow.Table\n",
      "valid_datetime: timestamp[ns, tz=UTC]\n",
      "payment_type: string\n",
      "payment_id: int64\n",
      "payment_status: string\n",
      "----\n",
      "valid_datetime: [[2024-01-11 23:01:49.090909090Z,2024-01-15 09:41:49.090909090Z]]\n",
      "payment_type: [[\"debit card\",\"debit card\"]]\n",
      "payment_id: [[1,2]]\n",
      "payment_status: [[\"failed\",\"pending\"]] <class 'pyarrow.lib.Table'>\n",
      "pyarrow.Table\n",
      "update_date: int64\n",
      "merchant_location: string\n",
      "user_location: string\n",
      "----\n",
      "update_date: [[1640995200000,1641632290909]]\n",
      "merchant_location: [[\"North\",\"East\"]]\n",
      "user_location: [[\"East\",\"West\"]] <class 'pyarrow.lib.Table'>\n",
      "pyarrow.Table\n",
      "user_age_group: string\n",
      "product_category: string\n",
      "transaction_type: string\n",
      "----\n",
      "user_age_group: [[\"26-35\",\"26-35\"]]\n",
      "product_category: [[\"clothing\",\"home\"]]\n",
      "transaction_type: [[\"online\",\"online\"]] <class 'pyarrow.lib.Table'>\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Request Data Using the Defined Access Collection and Desired Features\n",
    "import mloda\n",
    "from mloda_plugins.compute_framework.base_implementations.pyarrow.table import PyArrowTable\n",
    "\n",
    "\n",
    "all_features = order_features + payment_features + location_features + categorical_features\n",
    "\n",
    "# Retrieve data based on the specified feature list and access collection\n",
    "result = mloda.run_all(all_features, data_access_collection=data_access_collection, compute_frameworks={PyArrowTable})\n",
    "\n",
    "# Display the first five entries of each result table and its type\n",
    "for data in result:\n",
    "    print(data[:2], type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quantity  product_id  order_id  item_price\n",
      "0         6         282         1       74.86\n",
      "1         2         355         2      154.56 <class 'pandas.core.frame.DataFrame'>\n",
      "                       valid_datetime payment_type  payment_id payment_status\n",
      "0 2024-01-11 23:01:49.090909090+00:00   debit card           1         failed\n",
      "1 2024-01-15 09:41:49.090909090+00:00   debit card           2        pending <class 'pandas.core.frame.DataFrame'>\n",
      "     update_date merchant_location user_location\n",
      "0  1640995200000             North          East\n",
      "1  1641632290909              East          West <class 'pandas.core.frame.DataFrame'>\n",
      "  user_age_group product_category transaction_type\n",
      "0          26-35         clothing           online\n",
      "1          26-35             home           online <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# The data is initially loaded as a Pyarrow table. However, we can easily load it also as a PandasDataFrame.\n",
    "from mloda_plugins.compute_framework.base_implementations.pandas.dataframe import PandasDataFrame\n",
    "\n",
    "# Request data using the Pandas compute framework\n",
    "result = mloda.run_all(\n",
    "    all_features, data_access_collection=data_access_collection, compute_frameworks={PandasDataFrame}\n",
    ")\n",
    "\n",
    "# Display the first five entries of each result table and its type\n",
    "for data in result:\n",
    "    print(data[:2], type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting data structure differs based on the compute framework:\n",
      "\n",
      "    order_id\n",
      "0         1\n",
      "1         2\n",
      "2         3 <class 'pandas.core.frame.DataFrame'>\n",
      "The resulting data structure differs based on the compute framework:\n",
      "\n",
      " pyarrow.Table\n",
      "product_id: int64\n",
      "----\n",
      "product_id: [[282,355,395]] <class 'pyarrow.lib.Table'>\n"
     ]
    }
   ],
   "source": [
    "# Define features with specific compute frameworks\n",
    "order_id = Feature(name=\"order_id\", compute_framework=\"PandasDataFrame\")\n",
    "product_id = Feature(name=\"product_id\", compute_framework=\"PyArrowTable\")\n",
    "specific_framework_feature_list: List[Feature | str] = [order_id, product_id]\n",
    "\n",
    "# Request data for the defined features\n",
    "result = mloda.run_all(specific_framework_feature_list, data_access_collection=data_access_collection)\n",
    "\n",
    "# Display the first few rows and data types of the results\n",
    "for res in result:\n",
    "    print(\"The resulting data structure differs based on the compute framework:\")\n",
    "    print(\"\\n\", res[:3], type(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from two different sources is now combined into one feature within one data technology: \n",
      " pyarrow.Table\n",
      "product_id: int64\n",
      "order_id: int64\n",
      "quantity: int64\n",
      "----\n",
      "product_id: [[282,355,395,319,275,...,170,328,361,192,271]]\n",
      "order_id: [[1,2,3,4,5,...,96,97,98,99,100]]\n",
      "quantity: [[6,2,4,9,5,...,4,3,5,5,6]] <class 'pyarrow.lib.Table'> \n",
      "\n",
      "Final result:  pyarrow.Table\n",
      "ExampleMlLifeCycleJoin: int64\n",
      "----\n",
      "ExampleMlLifeCycleJoin: [[1,2,3]] \n",
      "Note: As no specific compute framework was defined for the result, the output could be in either format.\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating mloda's Flexibility with Different Data Technologies\n",
    "\n",
    "# Import required modules\n",
    "from typing import Any, List, Optional, Set\n",
    "\n",
    "from mloda.provider import FeatureGroup, FeatureSet\n",
    "from mloda.user import Feature, FeatureName, Options, Index, Link, JoinSpec\n",
    "from mloda_plugins.feature_group.input_data.read_file_feature import ReadFileFeature\n",
    "\n",
    "\n",
    "# Define the index for the join\n",
    "index = Index((\"order_id\",))\n",
    "\n",
    "\n",
    "# Extend ReadFileFeature to provide index columns\n",
    "class ReadFileFeatureJoin(ReadFileFeature):\n",
    "    @classmethod\n",
    "    def index_columns(cls) -> Optional[List[Index]]:\n",
    "        return [index]\n",
    "\n",
    "\n",
    "# Define the link between the features using JoinSpec\n",
    "link = Link.inner(JoinSpec(ReadFileFeatureJoin, index), JoinSpec(ReadFileFeatureJoin, index))\n",
    "\n",
    "\n",
    "# Create an example feature group to demonstrate joining\n",
    "class ExampleMlLifeCycleJoin(FeatureGroup):\n",
    "    # Define input features with different compute frameworks\n",
    "    def input_features(self, options: Options, feature_name: FeatureName) -> Optional[Set[Feature]]:\n",
    "        quantity = Feature(name=\"quantity\", compute_framework=\"PandasDataFrame\")\n",
    "        product_id = Feature(name=\"product_id\", compute_framework=\"PyArrowTable\")\n",
    "        return {product_id, quantity}\n",
    "\n",
    "    # Perform calculations on the joined data\n",
    "    @classmethod\n",
    "    def calculate_feature(cls, data: Any, features: FeatureSet) -> Any:\n",
    "        print(\n",
    "            \"Data from two different sources is now combined into one feature within one data technology: \\n\",\n",
    "            data,\n",
    "            type(data),\n",
    "            \"\\n\",\n",
    "        )\n",
    "        return {\"ExampleMlLifeCycleJoin\": [1, 2, 3]}\n",
    "\n",
    "\n",
    "# Run the pipeline\n",
    "result = mloda.run_all([\"ExampleMlLifeCycleJoin\"], data_access_collection=data_access_collection, links={link})\n",
    "\n",
    "\n",
    "# Display the final result\n",
    "print(\n",
    "    \"Final result: \",\n",
    "    result[0],\n",
    "    \"\\nNote: As no specific compute framework was defined for the result, the output could be in either format.\",\n",
    ")\n",
    "\n",
    "# Summary: mloda's abstraction layer enables complex process pipelines that handle different data technologies.\n",
    "# This decouples processes from the underlying data structure, ensuring flexibility and scalability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Have We Observed So Far?\n",
    "\n",
    "1. mloda unifies the interfaces for data for various sources, formats and technologies for the definition of the processes and applying the processes on the data. We used the FeatureGroup, the ComputeFramework and mlodaAPI as interfaces.\n",
    "\n",
    "2. It integrates with any techologies, e.g. PyArrow and Pandas, enabling flexible tool choices for data processing.\n",
    "\n",
    "3. mloda combines data access and computation, reducing complexity and providing a reusable approach to ML workflows. Data Access can be controlled centrally for different sources of data. Here, we showed folders and a database access.\n",
    "\n",
    "We will further deepen the advantages of the used approach in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

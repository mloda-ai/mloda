{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mloda + scikit-learn Integration: Basic Example\n",
    "\n",
    "This notebook demonstrates how mloda enhances scikit-learn workflows by providing reusable, manageable feature transformations.\n",
    "\n",
    "## Quick Comparison: Traditional sklearn vs mloda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Create Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data with missing values:\n",
      "    age     weight state gender\n",
      "0  56.0  90.585667    NY      F\n",
      "1  69.0  59.833209    NY      M\n",
      "2  46.0  87.302978    FL      F\n",
      "3  32.0  64.374841    FL      M\n",
      "4  60.0  59.587811    FL      M\n",
      "\n",
      "Data shape: (1000, 4)\n",
      "Missing values: age=50, weight=50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create realistic sample data with missing values\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "data_dict = {\n",
    "    \"age\": np.random.randint(18, 80, n_samples),\n",
    "    \"weight\": np.random.normal(70, 15, n_samples),\n",
    "    \"state\": np.random.choice([\"CA\", \"NY\", \"TX\", \"FL\"], n_samples),\n",
    "    \"gender\": np.random.choice([\"M\", \"F\"], n_samples),\n",
    "}\n",
    "\n",
    "data = pd.DataFrame(data_dict)\n",
    "\n",
    "# Introduce missing values\n",
    "missing_indices = np.random.choice(n_samples, size=int(0.1 * n_samples), replace=False)\n",
    "data.loc[missing_indices[:50], \"age\"] = np.nan\n",
    "data.loc[missing_indices[50:], \"weight\"] = np.nan\n",
    "\n",
    "print(\"Sample data with missing values:\")\n",
    "print(data.head())\n",
    "print(f\"\\nData shape: {data.shape}\")\n",
    "print(f\"Missing values: age={data['age'].isna().sum()}, weight={data['weight'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional scikit-learn Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Transformed dataset with split fit/transform:\n",
      "   state_CA  state_FL  state_NY  state_TX  gender_F  gender_M       age  \\\n",
      "0       0.0       0.0       1.0       0.0       1.0       0.0  0.351358   \n",
      "1       0.0       0.0       1.0       0.0       0.0       1.0  1.086080   \n",
      "\n",
      "     weight  \n",
      "0  1.287800  \n",
      "1 -0.705904  \n",
      "Traditional pipeline result shape: (1000, 8)\n",
      "Result: 8 columns total\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# numeric_preprocessor = Pipeline(\n",
    "numeric_preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputation_mean\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "categorical_preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"imputation_constant\",\n",
    "            SimpleImputer(fill_value=\"missing\", strategy=\"constant\"),\n",
    "        ),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"categorical\", categorical_preprocessor, [\"state\", \"gender\"]),\n",
    "        (\"numerical\", numeric_preprocessor, [\"age\", \"weight\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "preprocessor.fit(data)  # Learn imputations, encoder categories, and scaler parameters\n",
    "X_transformed = preprocessor.transform(data)  # Apply the transformations\n",
    "\n",
    "onehot_feature_names = (\n",
    "    preprocessor.named_transformers_[\"categorical\"].named_steps[\"onehot\"].get_feature_names_out([\"state\", \"gender\"])\n",
    ")\n",
    "numeric_feature_names = [\"age\", \"weight\"]\n",
    "all_feature_names = np.concatenate([onehot_feature_names, numeric_feature_names])\n",
    "\n",
    "df_transformed = pd.DataFrame(\n",
    "    X_transformed.toarray() if hasattr(X_transformed, \"toarray\") else X_transformed,  # type: ignore\n",
    "    columns=all_feature_names,\n",
    ")\n",
    "\n",
    "print(\"✅ Transformed dataset with split fit/transform:\")\n",
    "print(df_transformed.head(2))\n",
    "\n",
    "print(f\"Traditional pipeline result shape: {X_transformed.shape}\")\n",
    "print(f\"Result: {len(df_transformed.columns)} columns total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mloda Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/envs/python310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Transformed dataset with split fit/transform:\n",
      "   state__onehot_encoded~1  gender__onehot_encoded~0  state__onehot_encoded~0  \\\n",
      "0                      0.0                       1.0                      0.0   \n",
      "1                      0.0                       0.0                      0.0   \n",
      "\n",
      "   gender__onehot_encoded~1  state__onehot_encoded~2  state__onehot_encoded~3  \n",
      "0                       0.0                      1.0                      0.0  \n",
      "1                       1.0                      1.0                      0.0  \n",
      "   age__mean_imputed__standard_scaled  weight__mean_imputed__standard_scaled\n",
      "0                            0.339295                               1.243621\n",
      "1                            1.057320                              -0.677472\n",
      "Result: ['state__onehot_encoded~1', 'gender__onehot_encoded~0', 'state__onehot_encoded~0', 'gender__onehot_encoded~1', 'state__onehot_encoded~2', 'state__onehot_encoded~3'] \n",
      " ['age__mean_imputed__standard_scaled', 'weight__mean_imputed__standard_scaled'] columns total\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Any\n",
    "import mloda\n",
    "from mloda.provider import FeatureGroup, BaseInputData, DataCreator, FeatureSet\n",
    "from mloda.user import PluginLoader\n",
    "from mloda_plugins.compute_framework.base_implementations.pandas.dataframe import PandasDataFrame\n",
    "\n",
    "# In mloda, we have the concept of feature groups.\n",
    "# A feature group is an abstraction between a data framework and processes of a data transformation.\n",
    "# In this example, the data framework is clearly pandas.\n",
    "# The processes are typically meta information like names, but lifecyle definition, or dependencies or relations to other data.\n",
    "\n",
    "# On the basis on the given data_dict earlier defined and its names, we use a DataCreator to inject the data_dict into the feature group abstraction.\n",
    "# Very simply spoken: we load the data.\n",
    "\n",
    "\n",
    "class SklearnDataCreator(FeatureGroup):\n",
    "    # This function is core to mloda. In this spot, the data framework with the actual data representation meets the defined and resolved processes.\n",
    "    # With this, we have access to the before and after state of a feature.\n",
    "\n",
    "    @classmethod\n",
    "    def calculate_feature(cls, data: Any, features: FeatureSet) -> Any:\n",
    "        # If this feature would not load data, we would use the data given from the parameter \"data\".\n",
    "        data = pd.DataFrame(data_dict)\n",
    "        return data\n",
    "\n",
    "    # One way to get this data is via defined input_data. But there are many more and we should not go to deep into this topic for now.\n",
    "    @classmethod\n",
    "    def input_data(cls) -> Optional[BaseInputData]:\n",
    "        return DataCreator({\"age\", \"weight\", \"state\", \"gender\"})\n",
    "\n",
    "\n",
    "# As next, we will use one method of defining what features we want as result from the mloda framework.\n",
    "features = [\n",
    "    \"age__mean_imputed__standard_scaled\",  # Scale imputed age\n",
    "    \"weight__mean_imputed__standard_scaled\",  # Scale imputed weight\n",
    "    \"state__onehot_encoded\",  # One-hot encode state\n",
    "    \"gender__onehot_encoded\",  # One-hot encode gender\n",
    "]\n",
    "\n",
    "# We now use a trick to register all known feature groups. mloda will only use those which are loaded into the namespace.\n",
    "PluginLoader().all()\n",
    "\n",
    "# And then we execute mloda, which will resolve its dependencies of its feature groups and data frame technologies automatically.\n",
    "result = mloda.run_all(features, compute_frameworks={PandasDataFrame})\n",
    "_result, _result2 = result[0], result[1]\n",
    "print(\"✅ Transformed dataset with split fit/transform:\")\n",
    "print(_result.head(2))\n",
    "print(_result2.head(2))\n",
    "\n",
    "print(f\"Result: {list(_result.columns)} \\n {list(_result2.columns)} columns total\")\n",
    "\n",
    "# Remark 1: We have not yet added the functionality to map the value to a column string back. It is planned. https://github.com/mloda-ai/mloda/issues/46\n",
    "\n",
    "# Remark 2: If you see the error \"ValueError: Multiple feature groups\", please restart the notebook. This happens if we load the class SklearnDataCreator twice into the notebook memory.\n",
    "#         I have yet to find a solution for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   state__onehot_encoded~0\n",
      "0                      0.0\n",
      "1                      0.0    weight__mean_imputed__robust_scaled\n",
      "0                             0.938858\n",
      "1                            -0.535025    age__mean_imputed__standard_scaled__max_aggr\n",
      "0                                      1.609647\n",
      "1                                      1.609647\n"
     ]
    }
   ],
   "source": [
    "# The beauty and strength of mloda is that we can combine feature groups in a very creative way.\n",
    "chained_features = [\n",
    "    \"age__mean_imputed__standard_scaled__max_aggr\",  # Do feature pipelines\n",
    "    \"weight__mean_imputed__robust_scaled\",  # Different scaler for weight\n",
    "    \"state__onehot_encoded~0\",  # Access specific one-hot column\n",
    "]\n",
    "\n",
    "result = mloda.run_all(chained_features, compute_frameworks={PandasDataFrame})\n",
    "print(\n",
    "    result[0].head(2),\n",
    "    result[1].head(2),\n",
    "    result[2].head(2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I, SecondSklearnDataCreator AM NOW USED.\n",
      "   state__onehot_encoded~0\n",
      "0                      1.0\n",
      "1                      1.0    weight__mean_imputed__robust_scaled\n",
      "0                             0.677809\n",
      "1                            -0.293511    age__mean_imputed__standard_scaled__max_aggr\n",
      "0                                      1.631997\n",
      "1                                      1.631997\n"
     ]
    }
   ],
   "source": [
    "# We can replace feature groups and dataframe plugins in an easy fashion.\n",
    "from mloda.user import PluginCollector\n",
    "\n",
    "\n",
    "class SecondSklearnDataCreator(FeatureGroup):\n",
    "    @classmethod\n",
    "    def input_data(cls) -> Optional[BaseInputData]:\n",
    "        return DataCreator({\"age\", \"weight\", \"state\", \"gender\"})\n",
    "\n",
    "    @classmethod\n",
    "    def calculate_feature(cls, data: Any, features: FeatureSet) -> Any:\n",
    "        print(f\"I, {cls.get_class_name()} AM NOW USED.\")\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                \"age\": np.random.randint(25, 65, 500),\n",
    "                \"weight\": np.random.normal(80, 20, 500),  # Different distribution\n",
    "                \"state\": np.random.choice([\"WA\", \"OR\"], 500),  # Different states!\n",
    "                \"gender\": np.random.choice([\"M\", \"F\", \"Other\"], 500),  # New category!\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "chained_features = [\n",
    "    \"age__mean_imputed__standard_scaled__max_aggr\",  # Step 2: Scale imputed\n",
    "    \"weight__mean_imputed__robust_scaled\",  # Different scaler for weight\n",
    "    \"state__onehot_encoded~0\",  # Access specific one-hot column\n",
    "]\n",
    "\n",
    "# We deactivated now the other feature group, so that we use SecondSklearnDataCreator.\n",
    "result = mloda.run_all(\n",
    "    chained_features,\n",
    "    compute_frameworks={PandasDataFrame},\n",
    "    plugin_collector=PluginCollector.disabled_feature_groups(SklearnDataCreator),\n",
    ")\n",
    "print(\n",
    "    result[0].head(2),\n",
    "    result[1].head(2),\n",
    "    result[2].head(2),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
